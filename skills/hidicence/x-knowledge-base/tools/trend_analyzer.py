#!/usr/bin/env python3
"""
è¶¨å‹¢åˆ†æå™¨ - è‡ªæˆ‘é€²åŒ–æ ¸å¿ƒ
æ ¹æ“šæ›¸ç±¤å‚¾å‘è‡ªå‹•èª¿æ•´é—œéµå­—å’Œè¶¨å‹¢åˆ†æ
"""

import os
import re
import json
from pathlib import Path
from datetime import datetime, timedelta
from collections import Counter

BOOKMARKS_DIR = Path("/home/ubuntu/clawd/memory/bookmarks")
TRENDS_FILE = Path("/home/ubuntu/clawd/memory/interest-trends.json")
CONFIG_FILE = Path("/home/ubuntu/clawd/skills/x-knowledge-base/config/interests.yaml")

# é è¨­æ¨™ç±¤é…ç½®
DEFAULT_TAGS = {
    "ai": {"weight": 1.0, "category": "tech"},
    "video": {"weight": 1.0, "category": "content"},
    "seo": {"weight": 1.0, "category": "marketing"},
    "marketing": {"weight": 1.0, "category": "marketing"},
    "automation": {"weight": 1.0, "category": "tech"},
    "workflow": {"weight": 1.0, "category": "tech"},
    "prompt": {"weight": 1.0, "category": "tech"},
    "mcp": {"weight": 1.0, "category": "tech"},
}

def get_all_tags():
    """å¾æ‰€æœ‰æ›¸ç±¤æ“·å–æ¨™ç±¤"""
    tags_counter = Counter()
    tag_timeline = {}  # æ¯å€‹æ¨™ç±¤çš„æ™‚é–“ç·š
    
    for f in BOOKMARKS_DIR.rglob("*.md"):
        if f.name.startswith("."): continue
        if f.name in ["INDEX.md", "urls.txt"]: continue
        
        content = f.read_text(encoding='utf-8')
        
        # æ“·å–æ¨™ç±¤
        tags = re.findall(r'#(\w+)', content)
        
        # å¾æª”åæˆ–æ—¥æœŸä¼°ç®—æ™‚é–“
        date_match = re.search(r'(\d{4}-\d{2}-\d{2})', f.name)
        if date_match:
            date = date_match.group(1)
        else:
            # ä½¿ç”¨æª”æ¡ˆä¿®æ”¹æ™‚é–“
            date = datetime.fromtimestamp(f.stat().st_mtime).strftime('%Y-%m-%d')
        
        for tag in tags:
            tags_counter[tag] += 1
            if tag not in tag_timeline:
                tag_timeline[tag] = []
            tag_timeline[tag].append(date)
    
    return tags_counter, tag_timeline

def calculate_trends(tags_counter, tag_timeline):
    """è¨ˆç®—è¶¨å‹¢åˆ†æ•¸"""
    trends = {}
    
    # å–å¾—å‰ä¸€é€±çš„æ•¸æ“šä½œç‚ºåŸºæº–
    today = datetime.now()
    week_ago = today - timedelta(days=7)
    
    for tag, count in tags_counter.items():
        dates = sorted(tag_timeline.get(tag, []))
        
        # è¨ˆç®—é€™é€± vs ä¸Šé€±
        recent_count = sum(1 for d in dates if d >= week_ago.strftime('%Y-%m-%d'))
        older_count = count - recent_count
        
        # è¶¨å‹¢è¨ˆç®—
        if older_count > 0:
            change_percent = ((recent_count - older_count/2) / older_count) * 100
        elif recent_count > 0:
            change_percent = 100  # æ–°æ¨™ç±¤
        else:
            change_percent = 0
        
        # åˆ†é¡
        if change_percent > 50:
            status = "rising"  # ä¸Šå‡
        elif change_percent < -30:
            status = "falling"  # ä¸‹é™
        else:
            status = "stable"  # ç©©å®š
        
        trends[tag] = {
            "count": count,
            "recent": recent_count,
            "trend": change_percent,
            "status": status
        }
    
    return trends

def detect_emerging_trends(trends, threshold=50):
    """åµæ¸¬æ–°èˆˆè¶¨å‹¢ï¼ˆå¿«é€Ÿä¸Šå‡çš„æ¨™ç±¤ï¼‰"""
    emerging = []
    
    for tag, data in trends.items():
        if data["trend"] > threshold and data["count"] >= 3:
            emerging.append({
                "tag": tag,
                "trend": data["trend"],
                "count": data["count"]
            })
    
    # æŒ‰è¶¨å‹¢æ’åº
    emerging.sort(key=lambda x: x["trend"], reverse=True)
    return emerging

def generate_recommended_keywords(trends, top_n=5):
    """æ ¹æ“šè¶¨å‹¢ç”Ÿæˆæ¨è–¦é—œéµå­—"""
    # æ¬Šé‡ï¼šä¸Šå‡è¶¨å‹¢ > ç©©å®š > ä¸‹é™
    weighted = []
    
    for tag, data in trends.items():
        if data["status"] == "rising":
            weight = 1.5
        elif data["status"] == "falling":
            weight = 0.5
        else:
            weight = 1.0
        
        score = data["count"] * weight
        weighted.append((tag, score))
    
    # æ’åº
    weighted.sort(key=lambda x: x[1], reverse=True)
    
    # è½‰æ›ç‚ºé—œéµå­—æ ¼å¼
    keywords = []
    for tag, score in weighted[:top_n]:
        keywords.append(f"{tag} AI")
        keywords.append(f"{tag} trends 2026")
    
    return keywords[:top_n * 2]

def analyze_interest_shift(trends):
    """åˆ†æèˆˆè¶£è½‰è®Š"""
    rising = []
    falling = []
    
    for tag, data in trends.items():
        if data["status"] == "rising" and data["count"] >= 3:
            rising.append(tag)
        elif data["status"] == "falling" and data["count"] >= 5:
            falling.append(tag)
    
    return {
        "rising": rising,
        "falling": falling,
        "summary": f"èˆˆè¶£å¾ {', '.join(falling[:3]) if falling else 'ç„¡'} è½‰å‘ {', '.join(rising[:3]) if rising else 'ç„¡'}"
    }

def save_trends(trends, emerging, keywords, shift):
    """å„²å­˜è¶¨å‹¢æ•¸æ“š"""
    data = {
        "last_updated": datetime.now().isoformat(),
        "trends": trends,
        "emerging": emerging,
        "recommended_keywords": keywords,
        "interest_shift": shift
    }
    
    TRENDS_FILE.parent.mkdir(parents=True, exist_ok=True)
    TRENDS_FILE.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding='utf-8')
    
    return data

def generate_report():
    """ç”¢ç”Ÿè¶¨å‹¢å ±å‘Š"""
    print("ğŸ“Š èˆˆè¶£è¶¨å‹¢åˆ†æå ±å‘Š")
    print("=" * 50)
    
    # å–å¾—æ¨™ç±¤æ•¸æ“š
    tags_counter, tag_timeline = get_all_tags()
    print(f"âœ… æ‰¾åˆ° {len(tags_counter)} å€‹æ¨™ç±¤")
    
    # è¨ˆç®—è¶¨å‹¢
    trends = calculate_trends(tags_counter, tag_timeline)
    
    # åµæ¸¬æ–°èˆˆè¶¨å‹¢
    emerging = detect_emerging_trends(trends)
    
    # ç”Ÿæˆæ¨è–¦é—œéµå­—
    keywords = generate_recommended_keywords(trends)
    
    # åˆ†æèˆˆè¶£è½‰è®Š
    shift = analyze_interest_shift(trends)
    
    # å„²å­˜
    data = save_trends(trends, emerging, keywords, shift)
    
    # é¡¯ç¤ºå ±å‘Š
    print(f"\nğŸ”¥ æ–°èˆˆè¶¨å‹¢:")
    for e in emerging[:5]:
        print(f"  - {e['tag']}: +{e['trend']:.0f}% ({e['count']} ç¯‡)")
    
    print(f"\nğŸ“ˆ æ¨è–¦é—œéµå­—:")
    for kw in keywords[:5]:
        print(f"  - {kw}")
    
    print(f"\nğŸ”„ èˆˆè¶£è½‰è®Š:")
    print(f"  {shift['summary']}")
    
    return data

if __name__ == "__main__":
    generate_report()
