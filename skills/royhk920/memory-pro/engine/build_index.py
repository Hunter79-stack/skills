from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import os
from preprocess import preprocess_directory

def build_index():
    """
    æ§‹å»º FAISS ç´¢å¼•ä¸¦ä¿å­˜åˆ°æŒ‡å®šè·¯å¾‘
    """
    base_dir = os.path.dirname(os.path.abspath(__file__))
    index_dir = os.getenv("MEMORY_PRO_INDEX_DIR", base_dir)
    output_path = os.getenv("MEMORY_PRO_INDEX_PATH", os.path.join(index_dir, "memory.index"))
    sentences_path = os.path.join(index_dir, "sentences.txt")
    
    print("ğŸ” é–‹å§‹æ§‹å»ºç´¢å¼•...")
    
    model = SentenceTransformer('all-MiniLM-L6-v2')
    sentences = preprocess_directory()
    print(f"ğŸ“Š æ‰¾åˆ° {len(sentences)} å€‹æœ‰æ•ˆå¥å­")
    embeddings = model.encode(sentences)
    index = faiss.IndexFlatL2(embeddings.shape[1])
    faiss.normalize_L2(embeddings)
    index.add(embeddings)
    
    print(f"ğŸ’¾ ä¿å­˜ç´¢å¼•åˆ° {output_path}...")
    faiss.write_index(index, output_path)
    with open(sentences_path, "w", encoding="utf-8") as f:
        f.write("\n".join(sentences))
    print(f"âœ… ç´¢å¼•æ§‹å»ºå®Œæˆï¼åŒ…å« {len(sentences)} å€‹å¥å­")
    return sentences, index

if __name__ == "__main__":
    sentences, index = build_index()
